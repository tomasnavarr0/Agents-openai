{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from uuid import uuid4\n",
    "from agents import Agent, Runner, function_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunResult(input='Write a haiku about recursion in programming.', new_items=[MessageOutputItem(agent=Agent(name='Assistant', instructions='You are a helpful assistant', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again'), raw_item=ResponseOutputMessage(id='msg_67df094a40788190913161439deed60e0e73188225dadcb6', content=[ResponseOutputText(annotations=[], text='Code loops endlessly,  \\nFunctions call themselves again—  \\nInfinite in scope.', type='output_text')], role='assistant', status='completed', type='message'), type='message_output_item')], raw_responses=[ModelResponse(output=[ResponseOutputMessage(id='msg_67df094a40788190913161439deed60e0e73188225dadcb6', content=[ResponseOutputText(annotations=[], text='Code loops endlessly,  \\nFunctions call themselves again—  \\nInfinite in scope.', type='output_text')], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=43, output_tokens=16, total_tokens=59), referenceable_id='resp_67df0949e8e081909afe86267d7182170e73188225dadcb6')], final_output='Code loops endlessly,  \\nFunctions call themselves again—  \\nInfinite in scope.', input_guardrail_results=[], output_guardrail_results=[], _last_agent=Agent(name='Assistant', instructions='You are a helpful assistant', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "agent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\")\n",
    "\n",
    "result = Runner.run_sync(agent, \"Write a haiku about recursion in programming.\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunResult(input='Hola, ¿cómo estás?', new_items=[HandoffCallItem(agent=Agent(name='Triage agent', instructions='Handoff to the appropriate agent based on the language of the request.', handoff_description=None, handoffs=[Agent(name='Spanish agent', instructions='You only speak Spanish.', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again'), Agent(name='English agent', instructions='You only speak English', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again')], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again'), raw_item=ResponseFunctionToolCall(arguments='{}', call_id='call_hZXRDaDXGGjMLveUmftXmrme', name='transfer_to_spanish_agent', type='function_call', id='fc_67df094b4c148190ad4ddceefb24bdab026355e1e46ac8a2', status='completed'), type='handoff_call_item'), HandoffOutputItem(agent=Agent(name='Triage agent', instructions='Handoff to the appropriate agent based on the language of the request.', handoff_description=None, handoffs=[Agent(name='Spanish agent', instructions='You only speak Spanish.', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again'), Agent(name='English agent', instructions='You only speak English', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again')], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again'), raw_item={'call_id': 'call_hZXRDaDXGGjMLveUmftXmrme', 'output': \"{'assistant': 'Spanish agent'}\", 'type': 'function_call_output'}, source_agent=Agent(name='Triage agent', instructions='Handoff to the appropriate agent based on the language of the request.', handoff_description=None, handoffs=[Agent(name='Spanish agent', instructions='You only speak Spanish.', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again'), Agent(name='English agent', instructions='You only speak English', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again')], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again'), target_agent=Agent(name='Spanish agent', instructions='You only speak Spanish.', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again'), type='handoff_output_item'), MessageOutputItem(agent=Agent(name='Spanish agent', instructions='You only speak Spanish.', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again'), raw_item=ResponseOutputMessage(id='msg_67df094bd6ac8190b9986d08e532bf8a026355e1e46ac8a2', content=[ResponseOutputText(annotations=[], text='¡Hola! Estoy bien, gracias. ¿Y tú?', type='output_text')], role='assistant', status='completed', type='message'), type='message_output_item')], raw_responses=[ModelResponse(output=[ResponseFunctionToolCall(arguments='{}', call_id='call_hZXRDaDXGGjMLveUmftXmrme', name='transfer_to_spanish_agent', type='function_call', id='fc_67df094b4c148190ad4ddceefb24bdab026355e1e46ac8a2', status='completed')], usage=Usage(requests=1, input_tokens=303, output_tokens=14, total_tokens=317), referenceable_id='resp_67df094af78c8190a5f0b229d2f052b4026355e1e46ac8a2'), ModelResponse(output=[ResponseOutputMessage(id='msg_67df094bd6ac8190b9986d08e532bf8a026355e1e46ac8a2', content=[ResponseOutputText(annotations=[], text='¡Hola! Estoy bien, gracias. ¿Y tú?', type='output_text')], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=72, output_tokens=13, total_tokens=85), referenceable_id='resp_67df094b8e8c8190806d793c76dfe4f5026355e1e46ac8a2')], final_output='¡Hola! Estoy bien, gracias. ¿Y tú?', input_guardrail_results=[], output_guardrail_results=[], _last_agent=Agent(name='Spanish agent', instructions='You only speak Spanish.', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_agent = Agent(\n",
    "    name=\"Spanish agent\",\n",
    "    instructions=\"You only speak Spanish.\",\n",
    ")\n",
    "\n",
    "english_agent = Agent(\n",
    "    name=\"English agent\",\n",
    "    instructions=\"You only speak English\",\n",
    ")\n",
    "\n",
    "triage_agent = Agent(\n",
    "    name=\"Triage agent\",\n",
    "    instructions=\"Handoff to the appropriate agent based on the language of the request.\",\n",
    "    handoffs=[spanish_agent, english_agent],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "await Runner.run(triage_agent, input=\"Hola, ¿cómo estás?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Code(BaseModel):\n",
    "    code: str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "\n",
    "@function_tool\n",
    "def visit_despegar():\n",
    "    # Configurar opciones del navegador\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Ejecuta el navegador en modo headless (sin interfaz gráfica)\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "\n",
    "    # Ruta al chromedriver\n",
    "    service = Service('/usr/local/bin/chromedriver')  # Reemplaza con la ruta a tu chromedriver\n",
    "\n",
    "    # Inicializar el navegador\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    try:\n",
    "        # Navegar a Despegar\n",
    "        driver.get(\"https://www.despegar.com.ar\")\n",
    "\n",
    "        # Esperar a que la página cargue completamente\n",
    "        time.sleep(5)  # Espera estática de 5 segundos; puedes usar WebDriverWait para una espera más dinámica\n",
    "\n",
    "        # Tomar una captura de pantalla\n",
    "        screenshot_path = \"despegar_screenshot.png\"\n",
    "        driver.save_screenshot(screenshot_path)\n",
    "\n",
    "        # Obtener el contenido de la página\n",
    "        content = driver.page_source\n",
    "\n",
    "        return f\"Página Despegar visitada con éxito. Captura guardada en {screenshot_path}. Longitud del HTML: {len(content)} caracteres.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Se produjo un error al visitar Despegar: {e}\"\n",
    "\n",
    "    finally:\n",
    "        # Cerrar el navegador\n",
    "        driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playwright.async_api import async_playwright\n",
    "\n",
    "async def visit_despegar_async() -> str:\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(\"https://www.google.com.ar\")\n",
    "        await page.wait_for_load_state(\"networkidle\")\n",
    "        screenshot_path = \"despegar_screenshot.png\"\n",
    "        await page.screenshot(path=screenshot_path)\n",
    "        content = await page.content()\n",
    "        await browser.close()\n",
    "        return f\"Página Despegar visitada con éxito. Captura guardada en {screenshot_path}. Longitud del HTML: {len(content)} caracteres.\"\n",
    "\n",
    "@function_tool\n",
    "def get_weather(city: str) -> str:\n",
    "    return f\"The weather in {city} is sunny\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Página Despegar visitada con éxito. Captura guardada en despegar_screenshot.png. Longitud del HTML: 235335 caracteres.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await visit_despegar_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "programming_agent = Agent(\n",
    "    name=\"Weather agent\",\n",
    "    instructions=\"You are a weather agent, if the weather is sunny, go to Despegar.com.ar\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[visit_despegar, get_weather]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await Runner.run(programming_agent, input=\"give the weather in Rosario, Santa Fe. If the weather is good, go to Despegar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The weather in Rosario, Santa Fe is sunny! However, it seems there was an issue trying to access Despegar.com.ar. You might want to check the website directly for travel options.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "programming_agent = Agent(\n",
    "    name=\"Programmer agent\",\n",
    "    instructions=\"You are specialist in programming with python\",\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "math_agent = Agent(\n",
    "    name=\"Math agent\",\n",
    "    instructions=\"You are an expert in math and logic thinking\",\n",
    "    model=\"o3-mini\"\n",
    ")\n",
    "\n",
    "senior_agent = Agent(\n",
    "    name=\"Senior agent\",\n",
    "    instructions=\"You are a senior progammer who works in a multinational company. You have to check code and test quality\",\n",
    "    model=\"gpt-4\"\n",
    ")\n",
    "\n",
    "orchestrator_agent = Agent(\n",
    "    name=\"Project Manager\",\n",
    "    instructions=\"You are project manager who decides who have to work in the project\",\n",
    "    model=\"gpt-4o\",\n",
    "    handoffs=[programming_agent, math_agent, senior_agent],\n",
    "    handoff_description=\"You can use 3 agents, a senior agent who is a qa, A math agent that you can use for the logic, and a programming agent that programs\",\n",
    "    output_type=Code\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await Runner.run(orchestrator_agent, input=\"Create a project where i can send a number and i will gent the double of the number i send\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure! Here\\'s a simple Python project that allows you to send a number and get back its double. You can create a command-line application or use a simple web application. Below, I’ll provide an example of both approaches.\\n\\n### Command-Line Application\\n\\n1. **Create a file named `double_number.py`.**\\n2. **Add the following code:**\\n\\n```python\\ndef double_number(number):\\n    return number * 2\\n\\ndef main():\\n    try:\\n        user_input = float(input(\"Enter a number: \"))\\n        result = double_number(user_input)\\n        print(f\"The double of {user_input} is {result}.\")\\n    except ValueError:\\n        print(\"Please enter a valid number.\")\\n\\nif __name__ == \"__main__\":\\n    main()\\n```\\n\\n3. **Run the application:**\\n   - Open your terminal.\\n   - Navigate to the directory where `double_number.py` is located.\\n   - Run the script using the command: `python double_number.py`.\\n\\n### Web Application (Using Flask)\\n\\n1. **Install Flask if you haven\\'t already.** You can do that using pip:\\n   ```bash\\n   pip install Flask\\n   ```\\n\\n2. **Create a file named `app.py`.**\\n3. **Add the following code:**\\n\\n```python\\nfrom flask import Flask, request, render_template_string\\n\\napp = Flask(__name__)\\n\\nHTML_TEMPLATE = \\'\\'\\'\\n<!doctype html>\\n<title>Double a Number</title>\\n<h1>Double a Number</h1>\\n<form method=\"POST\">\\n    <input type=\"number\" step=\"any\" name=\"number\" required>\\n    <input type=\"submit\" value=\"Double it!\">\\n</form>\\n{% if result is not none %}\\n    <h2>The double of {{ number }} is {{ result }}.</h2>\\n{% endif %}\\n\\'\\'\\'\\n\\n@app.route(\\'/\\', methods=[\\'GET\\', \\'POST\\'])\\ndef double_number():\\n    result = None\\n    if request.method == \\'POST\\':\\n        number = float(request.form[\\'number\\'])\\n        result = number * 2\\n        return render_template_string(HTML_TEMPLATE, number=number, result=result)\\n    return render_template_string(HTML_TEMPLATE, result=result)\\n\\nif __name__ == \"__main__\":\\n    app.run(debug=True)\\n```\\n\\n4. **Run the application:**\\n   - Open your terminal.\\n   - Navigate to the directory where `app.py` is located.\\n   - Run the script using the command: `python app.py`.\\n   - Open your web browser and go to `http://127.0.0.1:5000`.\\n\\n### Explanation\\n\\n- **Command-Line App:** It prompts for user input, doubles the number, and displays the result.\\n- **Web App:** It provides an HTML form for the user to input a number, processes the form submission, and displays the doubled value on the same page.\\n\\nFeel free to modify and expand upon these examples! If you have any specific requirements or questions, let me know!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.final_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agents-openai-z6qCqrOp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
